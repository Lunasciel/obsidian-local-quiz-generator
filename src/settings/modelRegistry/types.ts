/**
 * Model Registry Types
 *
 * Core data model interfaces for the centralized model registry system.
 * This module provides types for configuring, storing, and managing LLM models
 * across the plugin's various features (main generation, consensus, council).
 *
 * Requirements: 1.1, 1.6, 4.1, 4.2
 */

import { Provider } from "../../generators/providers";

/**
 * Base interface for all provider-specific configurations.
 * Uses discriminated union pattern for type-safe provider handling.
 */
export interface BaseProviderConfig {
	/** The provider type - used as discriminator */
	provider: Provider;
}

/**
 * OpenAI-compatible provider configuration.
 * Includes API key, base URL, and model selections.
 */
export interface OpenAIProviderConfig extends BaseProviderConfig {
	provider: Provider.OPENAI;

	/** API key for authentication */
	apiKey: string;

	/** Base URL for the API (defaults to OpenAI's API, can be customized for LM Studio, etc.) */
	baseUrl: string;

	/** Model name/ID for text generation */
	textGenerationModel: string;

	/** Model name/ID for embeddings (optional - used for quiz answer evaluation) */
	embeddingModel: string;
}

/**
 * Ollama provider configuration.
 * Local-only provider requiring base URL and model selections.
 */
export interface OllamaProviderConfig extends BaseProviderConfig {
	provider: Provider.OLLAMA;

	/** Base URL for the Ollama API (typically http://localhost:11434) */
	baseUrl: string;

	/** Model name for text generation */
	textGenerationModel: string;

	/** Model name for embeddings (optional - used for quiz answer evaluation) */
	embeddingModel: string;
}

/**
 * Discriminated union of all provider configurations.
 * Use the `provider` field to discriminate between types.
 *
 * @example
 * ```typescript
 * function getApiKey(config: ProviderConfig): string | undefined {
 *   if (config.provider === Provider.OPENAI) {
 *     return config.apiKey; // TypeScript knows this is OpenAIProviderConfig
 *   }
 *   return undefined; // Ollama doesn't have an API key
 * }
 * ```
 */
export type ProviderConfig = OpenAIProviderConfig | OllamaProviderConfig;

/**
 * Complete configuration for a single model in the registry.
 * Each model has a unique ID, display name, and provider-specific settings.
 *
 * Requirements: 1.1, 3.1, 3.3, 4.1
 */
export interface ModelConfiguration {
	/** Unique identifier for this model (auto-generated, immutable after creation) */
	id: string;

	/** User-friendly display name (e.g., "Main OpenAI", "Local Llama 3") */
	displayName: string;

	/**
	 * Whether the display name was auto-generated from provider and model name.
	 * When true, the display name should be updated automatically when the
	 * text generation model changes. When false (custom name), preserve the name.
	 *
	 * Requirements: 3.1, 3.3
	 */
	isAutoGeneratedName: boolean;

	/** Provider-specific configuration (OpenAI or Ollama) */
	providerConfig: ProviderConfig;

	/** Timestamp when model was added to registry */
	createdAt: number;

	/** Timestamp when model was last modified */
	modifiedAt: number;
}

/**
 * The central model registry containing all configured models.
 * Provides a single source of truth for model configurations.
 *
 * Requirements: 1.1, 4.1
 */
export interface ModelRegistry {
	/** Map of model ID to model configuration */
	models: Record<string, ModelConfiguration>;

	/** Version number for migration compatibility */
	version: number;
}

/**
 * Locations where a model can be used in the plugin.
 */
export type ModelUsageLocation = "main" | "consensus" | "council" | "chair";

/**
 * Information about where a model is being used across the plugin.
 * Used to warn users before editing/deleting shared models.
 *
 * Requirements: 4.6, 7.3
 */
export interface ModelUsageInfo {
	/** The model ID being tracked */
	modelId: string;

	/** Whether this model is used as the main generation model */
	isMainModel: boolean;

	/** Whether this model is used in consensus mode */
	isInConsensus: boolean;

	/** Whether this model is used in council mode */
	isInCouncil: boolean;

	/** Whether this model is used as the council chair */
	isChairModel: boolean;

	/** List of all locations where model is used */
	usageLocations: ModelUsageLocation[];

	/** Total number of places this model is used */
	usageCount: number;
}

/**
 * Reference to a model in the registry for use in consensus settings.
 * Instead of storing full model configuration, consensus stores references.
 *
 * Requirements: 1.2, 2.1
 */
export interface ConsensusModelReference {
	/** Reference to model ID in the registry */
	modelId: string;

	/** Weight for this model in consensus voting (default: 1.0) */
	weight: number;

	/** Whether this model is enabled for consensus */
	enabled: boolean;
}

/**
 * Reference to a model in the registry for use in council settings.
 * Similar to consensus reference but for the council feature.
 *
 * Requirements: 1.3, 2.1
 */
export interface CouncilModelReference {
	/** Reference to model ID in the registry */
	modelId: string;

	/** Weight for this model in council ranking (default: 1.0) */
	weight: number;

	/** Whether this model is enabled for council */
	enabled: boolean;
}

/**
 * Default OpenAI provider configuration.
 */
export const DEFAULT_OPENAI_PROVIDER_CONFIG: OpenAIProviderConfig = {
	provider: Provider.OPENAI,
	apiKey: "",
	baseUrl: "https://api.openai.com/v1",
	textGenerationModel: "gpt-3.5-turbo",
	embeddingModel: "text-embedding-3-small",
};

/**
 * Default Ollama provider configuration.
 */
export const DEFAULT_OLLAMA_PROVIDER_CONFIG: OllamaProviderConfig = {
	provider: Provider.OLLAMA,
	baseUrl: "http://localhost:11434",
	textGenerationModel: "",
	embeddingModel: "",
};

/**
 * Default empty model registry.
 */
export const DEFAULT_MODEL_REGISTRY: ModelRegistry = {
	models: {},
	version: 1,
};

/**
 * Type guard to check if an object is a valid OpenAIProviderConfig.
 */
export function isOpenAIProviderConfig(obj: unknown): obj is OpenAIProviderConfig {
	if (obj === null || typeof obj !== "object") {
		return false;
	}
	const config = obj as Record<string, unknown>;
	return (
		config.provider === Provider.OPENAI &&
		typeof config.apiKey === "string" &&
		typeof config.baseUrl === "string" &&
		typeof config.textGenerationModel === "string" &&
		typeof config.embeddingModel === "string"
	);
}

/**
 * Type guard to check if an object is a valid OllamaProviderConfig.
 */
export function isOllamaProviderConfig(obj: unknown): obj is OllamaProviderConfig {
	if (obj === null || typeof obj !== "object") {
		return false;
	}
	const config = obj as Record<string, unknown>;
	return (
		config.provider === Provider.OLLAMA &&
		typeof config.baseUrl === "string" &&
		typeof config.textGenerationModel === "string" &&
		typeof config.embeddingModel === "string"
	);
}

/**
 * Type guard to check if an object is a valid ProviderConfig (either OpenAI or Ollama).
 */
export function isProviderConfig(obj: unknown): obj is ProviderConfig {
	return isOpenAIProviderConfig(obj) || isOllamaProviderConfig(obj);
}

/**
 * Type guard to check if an object is a valid ModelConfiguration.
 * Note: isAutoGeneratedName is optional for backward compatibility with existing
 * model configurations that were created before this field was added. When missing,
 * it defaults to false (treated as a custom name).
 */
export function isModelConfiguration(obj: unknown): obj is ModelConfiguration {
	if (obj === null || typeof obj !== "object") {
		return false;
	}
	const config = obj as Record<string, unknown>;
	// isAutoGeneratedName is optional for backward compatibility - defaults to false if missing
	const hasValidAutoGenFlag =
		config.isAutoGeneratedName === undefined ||
		typeof config.isAutoGeneratedName === "boolean";
	return (
		typeof config.id === "string" &&
		typeof config.displayName === "string" &&
		hasValidAutoGenFlag &&
		isProviderConfig(config.providerConfig) &&
		typeof config.createdAt === "number" &&
		typeof config.modifiedAt === "number"
	);
}

/**
 * Type guard to check if an object is a valid ModelRegistry.
 */
export function isModelRegistry(obj: unknown): obj is ModelRegistry {
	if (obj === null || typeof obj !== "object") {
		return false;
	}
	const registry = obj as Record<string, unknown>;
	if (typeof registry.version !== "number") {
		return false;
	}
	if (registry.models === null || typeof registry.models !== "object") {
		return false;
	}
	// Check that all entries in models are valid ModelConfiguration objects
	const models = registry.models as Record<string, unknown>;
	for (const key of Object.keys(models)) {
		if (!isModelConfiguration(models[key])) {
			return false;
		}
	}
	return true;
}

/**
 * Type guard to check if an object is a valid ModelUsageInfo.
 */
export function isModelUsageInfo(obj: unknown): obj is ModelUsageInfo {
	if (obj === null || typeof obj !== "object") {
		return false;
	}
	const info = obj as Record<string, unknown>;
	return (
		typeof info.modelId === "string" &&
		typeof info.isMainModel === "boolean" &&
		typeof info.isInConsensus === "boolean" &&
		typeof info.isInCouncil === "boolean" &&
		typeof info.isChairModel === "boolean" &&
		Array.isArray(info.usageLocations) &&
		typeof info.usageCount === "number"
	);
}

/**
 * Type guard to check if an object is a valid ConsensusModelReference.
 */
export function isConsensusModelReference(obj: unknown): obj is ConsensusModelReference {
	if (obj === null || typeof obj !== "object") {
		return false;
	}
	const ref = obj as Record<string, unknown>;
	return (
		typeof ref.modelId === "string" &&
		typeof ref.weight === "number" &&
		typeof ref.enabled === "boolean"
	);
}

/**
 * Type guard to check if an object is a valid CouncilModelReference.
 */
export function isCouncilModelReference(obj: unknown): obj is CouncilModelReference {
	if (obj === null || typeof obj !== "object") {
		return false;
	}
	const ref = obj as Record<string, unknown>;
	return (
		typeof ref.modelId === "string" &&
		typeof ref.weight === "number" &&
		typeof ref.enabled === "boolean"
	);
}

/**
 * Generate a unique model ID using timestamp and random suffix.
 * Format: model_<timestamp>_<random4chars>
 */
export function generateModelId(): string {
	const timestamp = Date.now();
	const randomSuffix = Math.random().toString(36).substring(2, 6);
	return `model_${timestamp}_${randomSuffix}`;
}

/**
 * Create a new ModelConfiguration with defaults.
 *
 * @param displayName - User-friendly name for the model
 * @param providerConfig - Provider-specific configuration
 * @param isAutoGeneratedName - Whether the display name was auto-generated (defaults to false)
 * @returns A new ModelConfiguration with generated ID and timestamps
 *
 * Requirements: 3.1, 3.3
 */
export function createModelConfiguration(
	displayName: string,
	providerConfig: ProviderConfig,
	isAutoGeneratedName: boolean = false
): ModelConfiguration {
	const now = Date.now();
	return {
		id: generateModelId(),
		displayName,
		isAutoGeneratedName,
		providerConfig,
		createdAt: now,
		modifiedAt: now,
	};
}

/**
 * Create a default ModelUsageInfo for a model that isn't used anywhere.
 *
 * @param modelId - The model ID to create usage info for
 * @returns ModelUsageInfo with all usage flags set to false
 */
export function createEmptyModelUsageInfo(modelId: string): ModelUsageInfo {
	return {
		modelId,
		isMainModel: false,
		isInConsensus: false,
		isInCouncil: false,
		isChairModel: false,
		usageLocations: [],
		usageCount: 0,
	};
}

/**
 * Get the provider display name for a provider config.
 *
 * @param providerConfig - The provider configuration
 * @returns Human-readable provider name
 */
export function getProviderDisplayName(providerConfig: ProviderConfig): string {
	switch (providerConfig.provider) {
		case Provider.OPENAI:
			return "OpenAI Compatible";
		case Provider.OLLAMA:
			return "Ollama";
		default:
			return "Unknown Provider";
	}
}

/**
 * Format a model configuration for display in dropdowns.
 * Format: "{DisplayName} ({Provider}: {GenerationModel} / {EmbeddingModel})"
 *
 * @param config - The model configuration
 * @returns Formatted display string
 */
export function formatModelForDisplay(config: ModelConfiguration): string {
	const provider = getProviderDisplayName(config.providerConfig);
	const genModel = config.providerConfig.textGenerationModel || "none";
	const embModel = config.providerConfig.embeddingModel || "none";
	return `${config.displayName} (${provider}: ${genModel} / ${embModel})`;
}
